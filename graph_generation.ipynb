{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook has been created to test graph analytics capabilities of GraphFrame on a sample dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries \n",
    "import graphframe as GF\n",
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create spark context\n",
    "sparkConf = (SparkConf().setMaster(\"local\").setAppName(\"SocialGraph\").set(\"spark.executor.memory\", \"2g\").set(\"spark.executor.instances\", \"4\"))\n",
    "sparkContext = SparkContext(conf=sparkConf)\n",
    "sql_context = SQLContext(sparkContext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Spark dataframe for group members data\n",
    "df_group_members = sql_context.read.format('com.databricks.spark.csv').options(header='true').load('data/group_members.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------+--------+\n",
      "|         create_time|         update_time|            group_id|             user_id|is_admin|added_by|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------+--------+\n",
      "|2016-06-25 12:12:...|2016-06-25 12:12:...|c8a5ca5947cc7d925...|fcaa201f972dfc428...|       f|    null|\n",
      "|2018-03-26 18:30:...|2018-03-26 18:30:...|d2c8410bb78af4615...|26cf4a8044866c1bc...|       f|    null|\n",
      "|2017-12-18 10:23:...|2017-12-18 10:23:...|2c07f080d9f041295...|570a2ddfdccc2b775...|       f|    null|\n",
      "|2018-02-08 16:58:...|2018-02-08 16:58:...|1430c9033779d7585...|df8d3021822ef6fed...|       f|    null|\n",
      "|2018-03-26 18:30:...|2018-03-26 18:30:...|d2c8410bb78af4615...|777862a1db383bcd7...|       f|    null|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_group_members.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select vertices column from Spark dataframe\n",
    "df_users = df_group_members.select(['user_id'])\n",
    "df_users = df_users.selectExpr(\"user_id as id\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate user_id entries and create vertices dataframe\n",
    "vertices=df_users.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id=u'b84ececc601c97d81eb0be2cac4b7950b3c2feb0'),\n",
       " Row(id=u'b988970fb04bc223621b0b8dbb8d3be615d1c7eb'),\n",
       " Row(id=u'e8c49ddb70edc78009cbd80195aca9938c415f87'),\n",
       " Row(id=u'21e9d66847d7c6392b9fcd105db203304e32416a'),\n",
       " Row(id=u'8f8cbcd1a3364ba1d44102963fc11f6bd09e1be8')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vertices.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the edges dataframe\n",
    "edges = df_group_members.select(col('user_id').alias('src'),col('group_id')).join(df_group_members.select(col('user_id').alias('dst'),col('group_id')), on=['group_id'], how='outer')\n",
    "edges = edges.select(col('src'),col('dst'),col('group_id')).filter(edges.src != edges.dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the graph\n",
    "graph = GF.GraphFrame(vertices, edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del vertices, edges, df_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the graph to file\n",
    "#graph.vertices.write.parquet('store/gv.parquet')\n",
    "#graph.edges.write.parquet('store/ge.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the graph from file\n",
    "#vertices = spark.read.parquet('store/gv.parquet')\n",
    "#edges = spark.read.parquet('store/ge.parquet')\n",
    "\n",
    "#graph = GraphFrame(vertices, edges)\n",
    "#graph.vertices.show(5)\n",
    "#graph.edges.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch 1st connects and 2nd connects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Spark dataframe for group to channel mapping data\n",
    "df_group_members = sql_context.read.format('com.databricks.spark.csv').options(header='true').load('data/group_channel.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group_members.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
