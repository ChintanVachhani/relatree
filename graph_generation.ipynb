{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook has been created to test graph analytics capabilities of GraphFrame on a sample dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries \n",
    "import graphframe as GF\n",
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Function: Create spark context\n",
    "Parameters: app_name, executor_memory, no_of_executors\n",
    "Returns: Spark SQLContext\n",
    "'''\n",
    "def createContext(app_name=\"SocialGraph\", executor_memory=\"2g\", no_of_executors=\"4\"):\n",
    "    sparkConf = (SparkConf().setMaster(\"local\").setAppName(app_name).set(\"spark.executor.memory\", executor_memory).set(\"spark.executor.instances\", no_of_executors))\n",
    "    sparkContext = SparkContext(conf=sparkConf)\n",
    "    sql_context = SQLContext(sparkContext)\n",
    "    return sql_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function: Create Spark dataframe from csv file\n",
    "Parameters: file_path,sql_context\n",
    "Returns: Pyspark Dataframe\n",
    "'''\n",
    "def loadData(file_path,sql_context):\n",
    "    df = sql_context.read.format('com.databricks.spark.csv').options(header='true').load(file_path)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function: Provide stats for a Pyspark Dataframe\n",
    "Parameters: Pyspark Dataframe\n",
    "Returns: N/A\n",
    "'''\n",
    "def getStats(df):\n",
    "    print(\"\\nRow count: %d\\n\\nColumn Count: %d\\n\\nColumn headers: %s\\n\\nSample Data:\\n\" %(df.count(),len(df.columns),df.columns))\n",
    "    df.show(5)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function: Create vertices dataframe\n",
    "Parameters: Pyspark Dataframe\n",
    "Returns: Pyspark dataframe depciting vertices\n",
    "'''\n",
    "def createVertices(df):\n",
    "    print(\"Creating Vertices DataFrame..\")\n",
    "    # Select user_Id [vertices] column from Spark dataframe\n",
    "    df_users = df.select(['user_id'])\n",
    "    df_users = df_users.selectExpr(\"user_id as id\") \n",
    "    # Remove duplicate user_id entries and create vertices dataframe\n",
    "    vertices = df_users.drop_duplicates()\n",
    "    print(\"Vertices DataFrame creation complete.\")\n",
    "    return vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function: Create edges dataframe\n",
    "Parameters: Pyspark Dataframe\n",
    "Returns: Pyspark dataframe depciting edges\n",
    "'''\n",
    "def createEdges(df):\n",
    "    # Create the edges dataframe\n",
    "    print(\"Creating Edges DataFrame..\")\n",
    "    edges = df.select(col('user_id').alias('src'),col('group_id')).join(df.select(col('user_id').alias('dst'),col('group_id')), on=['group_id'], how='outer')\n",
    "    edges = edges.select(col('src'),col('dst'),col('group_id')).filter(edges.src != edges.dst)\n",
    "    print(\"Edges DataFrame creation complete.\")\n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function: Create graph\n",
    "Parameters: Pyspark Dataframe - vertices, edges\n",
    "Returns: GraphFrame\n",
    "'''\n",
    "def createGraph(vertices, edges):\n",
    "    print(\"Creating graph..\")\n",
    "    # Generate the graph\n",
    "    graph = GF.GraphFrame(vertices, edges)\n",
    "    print(\"Graph creation complete.\")\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function: Save graph to file\n",
    "Parameters: GraphFrame\n",
    "Returns: N/A\n",
    "'''\n",
    "def saveGraph(graph):\n",
    "    # Save the graph to a file\n",
    "    print(\"Saving graph to file..\")\n",
    "    graph.vertices.write.parquet('store/gv.parquet')\n",
    "    graph.edges.write.parquet('store/ge.parquet')\n",
    "    print(\"Graph has been saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function: Load graph from file\n",
    "Parameters: N/A\n",
    "Returns: GraphFrame\n",
    "'''\n",
    "def loadGraph(graph):\n",
    "    # Load the graph from file\n",
    "    print(\"\\nLoading graph data..\")\n",
    "    vertices = spark.read.parquet('store/gv.parquet')\n",
    "    edges = spark.read.parquet('store/ge.parquet')\n",
    "    print(\"\\Generating graph..\")\n",
    "    graph = GF.GraphFrame(vertices, edges)\n",
    "    print(\"\\nGraph load complete.\")\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function: Obtain the first connects of a given vertex\n",
    "Parameters: GraphFrame, vertex label\n",
    "Returns: GraphFrame of connected vertices and their edges\n",
    "'''\n",
    "def first_connects(graph, vertex):\n",
    "    first_connect_motifs = graph.find(\"(v1)-[e]->(v2)\").filter(\"v1.id == '\"+vertex+\"'\")\n",
    "    return first_connect_motifs.select(\"v2.id\",\"e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function: Delete dataframe to free memory\n",
    "Parameters: List of DataFrames\n",
    "Returns: N/A\n",
    "'''\n",
    "def cleanUp(df_list):\n",
    "    for df in df_list:\n",
    "        del df\n",
    "    print(\"\\nDataFrame clean up complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Row count: 20917620\n",
      "\n",
      "Column Count: 6\n",
      "\n",
      "Column headers: ['create_time', 'update_time', 'group_id', 'user_id', 'is_admin', 'added_by']\n",
      "\n",
      "Sample Data:\n",
      "\n",
      "+--------------------+--------------------+--------------------+--------------------+--------+--------+\n",
      "|         create_time|         update_time|            group_id|             user_id|is_admin|added_by|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------+--------+\n",
      "|2016-06-25 12:12:...|2016-06-25 12:12:...|c8a5ca5947cc7d925...|fcaa201f972dfc428...|       f|    null|\n",
      "|2018-03-26 18:30:...|2018-03-26 18:30:...|d2c8410bb78af4615...|26cf4a8044866c1bc...|       f|    null|\n",
      "|2017-12-18 10:23:...|2017-12-18 10:23:...|2c07f080d9f041295...|570a2ddfdccc2b775...|       f|    null|\n",
      "|2018-02-08 16:58:...|2018-02-08 16:58:...|1430c9033779d7585...|df8d3021822ef6fed...|       f|    null|\n",
      "|2018-03-26 18:30:...|2018-03-26 18:30:...|d2c8410bb78af4615...|777862a1db383bcd7...|       f|    null|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------+--------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "Row count: 13150793\n",
      "\n",
      "Column Count: 2\n",
      "\n",
      "Column headers: ['group_id', 'channel_id']\n",
      "\n",
      "Sample Data:\n",
      "\n",
      "+--------------------+----------+\n",
      "|            group_id|channel_id|\n",
      "+--------------------+----------+\n",
      "|768808012f4a55a3c...|  football|\n",
      "|c2de90421fafd6c9b...|  football|\n",
      "|c42dd8dcc1ba6469e...|     promo|\n",
      "|baccbd59003ffd22d...|basketball|\n",
      "|3aa92e503fbdd905c...|  olympics|\n",
      "+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Create Spark context\n",
    "    sql_context = createContext(app_name=\"SocialGraph\", executor_memory=\"2g\", no_of_executors=\"4\")\n",
    "    \n",
    "    # Load group to member data into a Pyspark Dataframe\n",
    "    df_group_members = loadData('data/group_members.csv',sql_context)\n",
    "    \n",
    "    # Load group to channel data into a Pyspark Dataframe\n",
    "    df_group_channels = loadData('data/group_channel.csv',sql_context)\n",
    "    \n",
    "    # Get stats on group members and group channels dataframes\n",
    "    getStats(df_group_members)\n",
    "    getStats(df_group_channels)\n",
    "    \n",
    "    # Create vertices dataframe\n",
    "    vertices = createVertices(df_group_members)\n",
    "    \n",
    "    # Create edges dataframe\n",
    "    edges = createEdges(df_group_members)\n",
    "    \n",
    "    # Get stats on vertices and edges dataframes\n",
    "    getStats(vertices)\n",
    "    getStats(edges)\n",
    "    \n",
    "    # Create Graph\n",
    "    duta_graph = createGraph(vertices,edges)\n",
    "    \n",
    "    # Save Graph to file \n",
    "    #saveGraph(duta_graph)\n",
    "    \n",
    "    # Load graph from file\n",
    "    #duta_graph = loadGraph()\n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
